# ğŸ›ï¸ Walmart Demand Predictor MLOps: PrevisÃ£o de Demanda para Categorias Chave de Produtos no Varejo AlimentÃ­cio ğŸš€

ğŸ“Š Projeto final da disciplina CET0621 - Aprendizado de MÃ¡quina na AnÃ¡lise de Dados (Unicamp - Faculdade de Tecnologia). Este trabalho foca no desenvolvimento de um sistema de previsÃ£o de vendas semanais para diferentes categorias de produtos (departamentos) da rede Walmart, utilizando uma abordagem estruturada de aprendizado de mÃ¡quina.

---

## ğŸ“ DescriÃ§Ã£o do Projeto

Este projeto desenvolve um modelo de aprendizado de mÃ¡quina para prever as vendas semanais por categoria (departamento) e loja na rede Walmart. Utilizando um pipeline completo de ciÃªncia de dados â€“ da limpeza Ã  modelagem avanÃ§ada com dados histÃ³ricos e contextuais â€“ buscamos gerar previsÃµes precisas para otimizar estoques e o planejamento estratÃ©gico no varejo alimentÃ­cio, seguindo boas prÃ¡ticas de organizaÃ§Ã£o e reprodutibilidade.

---

## ğŸ¯ Problema Abordado

A previsÃ£o acurada da demanda Ã© vital no varejo alimentÃ­cio, onde erros geram perdas por excesso de estoque (desperdÃ­cio) ou por falta de produtos (vendas perdidas e clientes insatisfeitos). Este projeto enfrenta esse desafio aplicando tÃ©cnicas de regressÃ£o do aprendizado de mÃ¡quina para estimar as vendas semanais por categoria de produto, visando maior eficiÃªncia e rentabilidade.

---

## ğŸ’¾ Dataset Utilizado

O estudo Ã© baseado no dataset "Walmart Recruiting - Store Sales Forecasting", disponibilizado na plataforma Kaggle. Este conjunto de dados oferece um rico histÃ³rico contendo:
* Vendas semanais detalhadas por loja e departamento (nossa proxy para "categoria chave de produto").
* CaracterÃ­sticas das lojas (ex: tipo, tamanho).
* Fatores contextuais e promocionais (ex: temperatura, preÃ§o do combustÃ­vel, remarcaÃ§Ãµes promocionais, CPI, taxa de desemprego, indicadores de feriados).

ğŸ”— **Fonte do Dataset:** [Walmart Recruiting - Store Sales Forecasting](https://www.kaggle.com/competitions/walmart-recruiting-store-sales-forecasting/data)

---

## ğŸ› ï¸ Metodologia e Workflow Aplicados

O projeto seguiu as etapas fundamentais do processo de Descoberta de Conhecimento em Dados (KDD), adaptadas para um fluxo de trabalho de aprendizado de mÃ¡quina:

1.  **ğŸ“¥ Carregamento e UnificaÃ§Ã£o dos Dados:** CombinaÃ§Ã£o dos arquivos CSV (`train`, `test`, `stores`, `features`) em dataframes estruturados.
2.  **ğŸ§¹ Limpeza e ValidaÃ§Ã£o de Dados:**
    * ConversÃ£o e validaÃ§Ã£o de tipos de dados (datas, numÃ©ricos, etc.).
    * Tratamento de valores inconsistentes (ex: vendas negativas, markdowns negativos foram ajustados para 0).
    * VerificaÃ§Ã£o e tratamento de dados duplicados (nÃ£o foram encontradas duplicatas significativas).
3.  **ğŸ©¹ Tratamento de Valores Ausentes (NaNs):**
    * Preenchimento de NaNs nas colunas `MarkDown1-5` com 0 (indicando ausÃªncia de promoÃ§Ã£o).
    * Preenchimento de NaNs em `CPI` e `Unemployment` usando estratÃ©gias de preenchimento progressivo (`ffill`) e regressivo (`bfill`) agrupados por loja, garantindo consistÃªncia temporal.
4.  **ğŸ”„ TransformaÃ§Ã£o de VariÃ¡veis:**
    * AplicaÃ§Ã£o de One-Hot Encoding para a variÃ¡vel categÃ³rica `Type` (tipo de loja).
    * ConversÃ£o da variÃ¡vel booleana `IsHoliday` para formato numÃ©rico (0/1).
5.  **âœ¨ Engenharia de Features (Crucial para Performance):**
    * **Temporais:** ExtraÃ§Ã£o de Ano, MÃªs, Dia, Semana do Ano, Dia da Semana, Dia do Ano.
    * **De Lag:** CriaÃ§Ã£o de features baseadas em `Weekly_Sales` de semanas anteriores (ex: lags de 1, 4, 12, 52 semanas) para capturar autocorrelaÃ§Ã£o e sazonalidade.
    * **De Janela MÃ³vel:** CÃ¡lculo de estatÃ­sticas (mÃ©dia, mediana, soma, desvio padrÃ£o) de `Weekly_Sales` sobre janelas de tempo passadas (ex: janelas de 4, 8, 12, 26, 52 semanas) para capturar tendÃªncias recentes e suavizar ruÃ­dos.
    * Tratamento de NaNs introduzidos pela criaÃ§Ã£o de lags e janelas mÃ³veis (preenchidos com 0).
6.  **ğŸ“Š DivisÃ£o EstratÃ©gica dos Dados:** SeparaÃ§Ã£o do conjunto de treino em um novo subconjunto de treino e um conjunto de validaÃ§Ã£o, utilizando uma abordagem cronolÃ³gica para simular um cenÃ¡rio de previsÃ£o real.
7.  **ğŸ¤– Modelagem Preditiva e AvaliaÃ§Ã£o:**
    * DefiniÃ§Ã£o das variÃ¡veis X (features) e y (alvo - `Weekly_Sales`).
    * Treinamento e avaliaÃ§Ã£o comparativa de mÃºltiplos modelos de regressÃ£o:
        * RegressÃ£o Linear (como baseline).
        * Ãrvore de DecisÃ£o Regressora.
        * Random Forest Regressor.
        * Gradient Boosting Regressor.
    * AvaliaÃ§Ã£o de performance utilizando mÃ©tricas chave: Erro MÃ©dio Absoluto (MAE), Raiz do Erro QuadrÃ¡tico MÃ©dio (RMSE) e Coeficiente de DeterminaÃ§Ã£o (RÂ²), todas calculadas no conjunto de validaÃ§Ã£o.
8.  **ğŸš€ Treinamento do Modelo Final e GeraÃ§Ã£o de PrevisÃµes:**
    * Treinamento do modelo de melhor desempenho (Random Forest) utilizando o conjunto de treino completo (treino + validaÃ§Ã£o).
    * GeraÃ§Ã£o de previsÃµes para o conjunto de teste.
9.  **ğŸ“„ FormataÃ§Ã£o para SubmissÃ£o:** PreparaÃ§Ã£o do arquivo `random_forest_predictions_walmart.csv` com as previsÃµes finais.

---

## ğŸ’» Tecnologias e Bibliotecas

* **Linguagem:** Python 3.x
* **Bibliotecas Centrais:**
    * `pandas`: Para manipulaÃ§Ã£o e anÃ¡lise eficiente de dados tabulares.
    * `numpy`: Para operaÃ§Ãµes numÃ©ricas e suporte a arrays.
    * `scikit-learn`: Para prÃ©-processamento, implementaÃ§Ã£o dos modelos de machine learning e cÃ¡lculo das mÃ©tricas de avaliaÃ§Ã£o.
    * `matplotlib` e `seaborn`: Para a criaÃ§Ã£o de visualizaÃ§Ãµes e grÃ¡ficos.
* **Ambiente de Desenvolvimento:** Google Colaboratory (Colab) e VS Code