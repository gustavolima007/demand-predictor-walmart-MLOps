# ğŸ›’ Walmart Demand Predictor MLOps: PrevisÃ£o de Demanda para Categorias Chave no Varejo AlimentÃ­cio ğŸš€

ğŸ“Š **Projeto Final da Disciplina CET0621 - Aprendizado de MÃ¡quina na AnÃ¡lise de Dados**  
*Unicamp - Faculdade de Tecnologia*  
Este projeto desenvolve um sistema de previsÃ£o de vendas semanais por categoria (departamento) e loja na rede Walmart, utilizando um pipeline completo de ciÃªncia de dados. O objetivo Ã© gerar previsÃµes precisas para otimizar estoques e estratÃ©gias no varejo alimentÃ­cio, seguindo boas prÃ¡ticas de MLOps e reprodutibilidade.

---

## ğŸ“– DescriÃ§Ã£o do Projeto

Este trabalho implementa um modelo de aprendizado de mÃ¡quina baseado em Random Forest para prever vendas semanais, integrando dados histÃ³ricos e contextuais em um pipeline estruturado. Desde a limpeza e engenharia de features atÃ© a avaliaÃ§Ã£o e otimizaÃ§Ã£o do modelo, o projeto busca oferecer uma soluÃ§Ã£o prÃ¡tica para o desafio de previsÃ£o de demanda, reduzindo perdas por excesso ou falta de estoque no varejo alimentÃ­cio.

---

## ğŸ¯ Problema Abordado

A previsÃ£o precisa da demanda Ã© essencial no varejo alimentÃ­cio, onde erros podem levar a desperdÃ­cios (excesso de estoque) ou perda de vendas e insatisfaÃ§Ã£o do cliente (falta de produtos). Este projeto aborda esse desafio aplicando tÃ©cnicas de regressÃ£o para estimar vendas semanais por departamento, visando melhorar a eficiÃªncia operacional e a rentabilidade da rede Walmart.

---

## ğŸ’¾ Dataset Utilizado

O projeto utiliza o dataset "Walmart Recruiting - Store Sales Forecasting", disponÃ­vel na plataforma Kaggle. Este conjunto contÃ©m:
- **Vendas semanais**: Detalhadas por loja e departamento (proxy para categorias de produtos).
- **CaracterÃ­sticas das lojas**: Tipo (A, B, C) e tamanho.
- **Fatores contextuais**: Temperatura, preÃ§o do combustÃ­vel, descontos promocionais (MarkDown1-5), Ãndice de PreÃ§os ao Consumidor (CPI), taxa de desemprego, e indicadores de feriados (IsHoliday).
- **PerÃ­odo**: Treino (fevereiro de 2010 a outubro de 2012) e teste (novembro de 2012 a julho de 2013).

ğŸ”— **[Fonte do Dataset](https://www.kaggle.com/competitions/walmart-recruiting-store-sales-forecasting/data)**

---

## ğŸ› ï¸ Metodologia e Workflow

O desenvolvimento seguiu um fluxo de trabalho estruturado baseado no processo de Descoberta de Conhecimento em Dados (KDD), adaptado para MLOps:

1. **ğŸ“¥ Carregamento e IntegraÃ§Ã£o de Dados**  
   - CombinaÃ§Ã£o dos arquivos CSV (`train.csv`, `test.csv`, `stores.csv`, `features.csv`) em dataframes unificados.

2. **ğŸ§¹ Limpeza e ValidaÃ§Ã£o**  
   - ValidaÃ§Ã£o de tipos de dados (datas, numÃ©ricos).
   - CorreÃ§Ã£o de valores inconsistentes (ex.: vendas e markdowns negativos ajustados para 0).
   - AusÃªncia de duplicatas significativas detectada.

3. **ğŸ©¹ Tratamento de Valores Ausentes (NaNs)**  
   - Preenchimento de `MarkDown1-5` com 0 (ausÃªncia de promoÃ§Ãµes).
   - Uso de preenchimento progressivo (`ffill`) e regressivo (`bfill`) agrupado por loja para `CPI` e `Unemployment`, preservando a consistÃªncia temporal.

4. **ğŸ”„ TransformaÃ§Ã£o de VariÃ¡veis**  
   - One-Hot Encoding para `Type` (gerando `Type_A`, `Type_B`, `Type_C`).
   - ConversÃ£o de `IsHoliday` para formato numÃ©rico (0/1).

5. **âœ¨ Engenharia de Features**  
   - **Temporais**: ExtraÃ§Ã£o de `Year`, `Month`, `Day`, `WeekOfYear`, `DayOfWeek`, `DayOfYear`.
   - **Lags**: Features baseadas em `Weekly_Sales` de semanas anteriores (ex.: lags de 1, 4, 12, 52 semanas) para capturar autocorrelaÃ§Ã£o e sazonalidade.
   - **Janelas MÃ³veis**: EstatÃ­sticas (mÃ©dia, mediana, soma, desvio padrÃ£o) sobre janelas de 4, 8, 12, 26 e 52 semanas para identificar tendÃªncias.
   - Tratamento de NaNs resultantes com preenchimento por 0.

6. **ğŸ“Š DivisÃ£o dos Dados**  
   - SeparaÃ§Ã£o cronolÃ³gica em treino (2010-02-05 a 2012-07-06), validaÃ§Ã£o (2012-07-13 a 2012-10-26) e teste (novembro de 2012 a julho de 2013), simulando cenÃ¡rios reais.

7. **ğŸ¤– Modelagem e AvaliaÃ§Ã£o**  
   - Modelos testados: RegressÃ£o Linear, Ãrvore de DecisÃ£o, Random Forest, Gradient Boosting.
   - MÃ©tricas de avaliaÃ§Ã£o: MAE, RMSE e RÂ² no conjunto de validaÃ§Ã£o.
   - Random Forest otimizado com `n_estimators=30`, `max_depth=7`, etc., via RandomizedSearchCV.

8. **ğŸš€ Treinamento Final e PrevisÃµes**  
   - Retrainamento com conjunto completo e geraÃ§Ã£o de previsÃµes para o teste.
   - ExportaÃ§Ã£o do arquivo `random_forest_predictions_walmart.csv`.

---

## ğŸ“ˆ Resultados

O modelo Random Forest otimizado alcanÃ§ou RÂ² de 0.9833, MAE de 1397.38 e RMSE de 2825.27 no conjunto de validaÃ§Ã£o, superando os baselines. A validaÃ§Ã£o cruzada de 5-fold apresentou RMSE de 5938.36 (Â±910.41), indicando robustez. Features como `Weekly_Sales_lag_1` e `Weekly_Sales_roll_mean_4` foram as mais influentes, capturando padrÃµes temporais. Apesar da alta precisÃ£o, uma skewness de 1.66 nos resÃ­duos sugere leve subestimaÃ§Ã£o em vendas altas, apontando Ã¡reas para refinamento.

---

## ğŸ’» Tecnologias e Bibliotecas

- **Linguagem**: Python 3.13.4
- **Bibliotecas**:
  - `pandas`: ManipulaÃ§Ã£o de dados tabulares.
  - `numpy`: OperaÃ§Ãµes numÃ©ricas.
  - `scikit-learn`: Modelagem e mÃ©tricas.
  - `matplotlib` e `seaborn`: VisualizaÃ§Ãµes.
- **Ambiente**: Google Colab e VS Code.

---

## ğŸ“‹ InstruÃ§Ãµes de Uso

1. **PrÃ©-requisitos**:
   - Instale as dependÃªncias: `pip install -r requirements.txt` (crie um `requirements.txt` com as bibliotecas listadas).
   - FaÃ§a o clone do repositorio.

2. **ExecuÃ§Ã£o**:
   - Execute o notebook principal (`PrevisÃ£o_de_Demanda_para_Categorias_Chave_de_Produtos_no_Varejo_AlimentÃ­cio.ipynb`) no Colab/VS Code.
   - Ajuste os caminhos dos arquivos no cÃ³digo, se necessÃ¡rio.

3. **SaÃ­da**:
   - PrevisÃµes salvas em `random_forest_predictions_walmart.csv`.